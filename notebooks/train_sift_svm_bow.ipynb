{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f6c03c-a187-42cd-b54f-1ce428dd5824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: opencv-contrib-python in ./miniconda3/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: scikit-learn in ./miniconda3/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in ./miniconda3/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: tqdm in ./miniconda3/lib/python3.12/site-packages (4.66.2)\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./miniconda3/lib/python3.12/site-packages (from opencv-contrib-python) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./miniconda3/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./miniconda3/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./miniconda3/lib/python3.12/site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./miniconda3/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/lib/python3.12/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in ./miniconda3/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./miniconda3/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./miniconda3/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-contrib-python scikit-learn matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c9ca27-e6e3-4803-80a7-fb6eb43b9510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting SIFT: 100%|██████████| 12000/12000 [02:25<00:00, 82.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram shape: (11921, 100)\n",
      "Label count: 11921\n",
      "Unique labels: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "✅ Training complete.\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Agriculture       0.51      0.56      0.53       160\n",
      "     Airport       0.39      0.41      0.40       160\n",
      "       Beach       0.62      0.35      0.45       160\n",
      "        City       0.39      0.69      0.50       160\n",
      "      Desert       0.49      0.28      0.36       151\n",
      "      Forest       0.63      0.84      0.72       160\n",
      "   Grassland       0.55      0.34      0.42       155\n",
      "     Highway       0.51      0.44      0.47       160\n",
      "        Lake       0.31      0.10      0.15       159\n",
      "    Mountain       0.50      0.73      0.59       160\n",
      "     Parking       0.89      0.78      0.83       160\n",
      "        Port       0.55      0.46      0.50       160\n",
      "     Railway       0.49      0.65      0.56       160\n",
      " Residential       0.45      0.79      0.58       160\n",
      "       River       0.29      0.14      0.19       160\n",
      "\n",
      "    accuracy                           0.51      2385\n",
      "   macro avg       0.50      0.50      0.48      2385\n",
      "weighted avg       0.50      0.51      0.48      2385\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 89   4   0   3  15   1   3   7   4   3   1   0   3  20   7]\n",
      " [ 10  65   0  21   1   2   1   4   1   4   1  15  21   7   7]\n",
      " [ 14   4  56  14   1   4   3  12   9  16   0   4   4  10   9]\n",
      " [  1  17   1 111   1   2   0   0   0   1   0  11   5   9   1]\n",
      " [  4   0   1   1  43  16  19   4   1  28   5   1  11  15   2]\n",
      " [  1   0   0   7   2 134   7   1   0   5   0   1   0   2   0]\n",
      " [ 14   4   6   1  10  29  53   7   4   4   1   3   4  11   4]\n",
      " [  3  15   2   8   1   2   0  71   3   1   1   1  33  18   1]\n",
      " [ 12   7  12  14   2   7   4  12  16  26   1   5   3  23  15]\n",
      " [  0   1   4  11   4   2   0   1   0 117   0   0   6  12   2]\n",
      " [  0   9   0   3   2   0   2   1   2   2 125   0   4   7   3]\n",
      " [  0  16   1  44   0   1   0   3   4   2   4  73   9   1   2]\n",
      " [  1   8   0  18   0   0   0  12   0   5   0  11 104   1   0]\n",
      " [  1   8   0  14   2   1   0   0   1   1   1   0   1 127   3]\n",
      " [ 24  10   7  15   4  11   4   5   7  20   1   8   3  18  23]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATA_DIR = '/root/Aerial_Landscapes'\n",
    "NUM_CLASSES = 15\n",
    "NUM_CLUSTERS = 100\n",
    "LIMIT = None\n",
    "\n",
    "def load_image_paths(root_dir, limit=None):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(root_dir))\n",
    "    class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "\n",
    "    for cls in class_names:\n",
    "        cls_path = os.path.join(root_dir, cls)\n",
    "        count = 0\n",
    "        for img_name in os.listdir(cls_path):\n",
    "            if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_paths.append(os.path.join(cls_path, img_name))\n",
    "                labels.append(class_to_idx[cls])\n",
    "                count += 1\n",
    "                if limit and count >= limit:\n",
    "                    break\n",
    "    return image_paths, labels, class_names\n",
    "\n",
    "def extract_sift_descriptors(image_paths, labels):\n",
    "    sift = cv2.SIFT_create()\n",
    "    descriptors_list = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for i, path in enumerate(tqdm(image_paths, desc=\"Extracting SIFT\")):\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "        if descriptors is not None:\n",
    "            descriptors_list.append(descriptors)\n",
    "            valid_labels.append(labels[i])\n",
    "\n",
    "    return descriptors_list, valid_labels\n",
    "\n",
    "def build_vocabulary(descriptor_list, num_clusters):\n",
    "    all_descriptors = np.vstack(descriptor_list)\n",
    "\n",
    "    if len(all_descriptors) > 100000:\n",
    "        np.random.shuffle(all_descriptors)\n",
    "        all_descriptors = all_descriptors[:100000]\n",
    "\n",
    "    kmeans = MiniBatchKMeans(n_clusters=num_clusters, batch_size=1000, random_state=42)\n",
    "    kmeans.fit(all_descriptors)\n",
    "    return kmeans\n",
    "\n",
    "\n",
    "def extract_bow_histograms(descriptor_list, kmeans):\n",
    "    histograms = []\n",
    "    for descriptors in descriptor_list:\n",
    "        if descriptors is None:\n",
    "            histograms.append(np.zeros(kmeans.n_clusters))\n",
    "            continue\n",
    "        words = kmeans.predict(descriptors)\n",
    "        hist, _ = np.histogram(words, bins=np.arange(kmeans.n_clusters + 1))\n",
    "        hist = hist.astype('float32')\n",
    "        hist /= (hist.sum() + 1e-7)\n",
    "        histograms.append(hist)\n",
    "    return np.array(histograms)\n",
    "\n",
    "def train_and_evaluate(X, y, class_names):\n",
    "    print(\"Histogram shape:\", X.shape)\n",
    "    print(\"Label count:\", len(y))\n",
    "    print(\"Unique labels:\", np.unique(y))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "    clf = SVC(kernel='rbf', C=10, gamma=0.1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    np.save(f\"bow_histograms_{NUM_CLUSTERS}.npy\", histograms)\n",
    "    np.save(f\"bow_labels_{NUM_CLUSTERS}.npy\", np.array(labels))\n",
    "    print(\"✅ Training complete.\\n\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_paths, labels, class_names = load_image_paths(DATA_DIR, limit=LIMIT)\n",
    "    descriptors_list, labels = extract_sift_descriptors(image_paths, labels)\n",
    "    kmeans = build_vocabulary(descriptors_list, NUM_CLUSTERS)\n",
    "    histograms = extract_bow_histograms(descriptors_list, kmeans)\n",
    "    train_and_evaluate(histograms, labels, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a8934c-a273-4ef6-8bf3-a6c998dc0699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50a4c3c-11d3-4f9d-9180-c16ac96117ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a4e0f-68ea-471d-9905-fbc0c3c89084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
